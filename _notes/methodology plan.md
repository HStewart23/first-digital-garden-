---
title: methodology plan
---

## Research problem
([[research questions and hypothesis]])

RQ **How does the design of scholarly text analytic tools anticipate the information finding and processing behavior of those who use them ?**

#### goal:
To understand this specific subset of technologies to a degree where they can be used as an environment in which to understand and investigate digital browsing. 

#### initial state: 
Much research on browsing is conducted in physical libraries and then transposed onto digital settings. There are many good reasons for this, however it does limit the extent to which the unique capabilities of digital technologies can be discussed examined or developed in this vein. Features of the digital knowledge creation cycle such as the browsing potential in hypertext-like systems are overlooked by these traditions as there is no physical world alternative to such behavior.       

#### set of operations: 
This project leverages current browsing theory and applies it to the case study of text/corpus analysis systems/dashboards. These technologies embody a kind of browsing that is unique to the digital sphere. Among their uses they aim to enable the user to explore text in a non-linear fashion, looking through linked segments of text, showing frequently mentioned words or phrases and allowing the user transfer text into visual data such as graphs and diagrams.    

Specifically, this will be a case study approach of around 20 technologies that are all within the text analysis field and are self described as 'discovery' tools. The primary methodology will be the coding and analysis of numerous documents that surround these tools to analyses how their design anticipates users browse/ investigative/ discovery behavior using their tools. Among the documents being considered will be instruction/'help' documentation that accompany the tools, white papers, academic papers, and the designer's blog posts all of which can be found in the public domain. These documents will then be coded and analyzed looking at current browsing theory to examine if the anticipated behavior encoded into the tools is analogous to that described in the theory developed in physical libraries.

#### constraints: 
Browsing is not an overly large area of research and with the exceptions of some comparative studies () these technologies are rarely grouped together and examined as a body of data. As a consequence, the understanding of generalisable behavior in these environments is fragmented and not sufficient to conduct behavioral studies on users. This is the gap which this study will fill, paving the way for future use studies. 

Although most of these tools are accessible in English there are some - such as those associated with specific foreign language libraries that are not. Due to the small number of these and the diversity of languages that they represent, these will be removed from the data set. Perhaps in the future, scholars from the cultures represented by these technologies will see fit to iterate upon this work to include their own technologies and unique cultural perspective on browsing behavior. 

## Methodological fit and philosophy ([[methdological fit]] & [[research questions and hypothesis]])



## Implementation ([[document analysis]] & [[data gathering]] & [[coding]])

#### Data gathering
I used the [TAPoR (Text Analysis Portal for Research)](http://tapor.ca/home) collection of text mining tools to identify text analysis tools with a special focus on discovery. For each of the texts identified I pulled the text to analyze separately in nViVo and grabbed some screenshots to analyses the visual lay out of the manuals as well. I also pulled screenshots of the tools themselves for visual design analysis.

The primary data used in this research are instruction manuals, academic papers and blog posts. In so far as is possible all textual analysis tools that are currently maintained and openly available for scholarly use are represented in this sample in some way. The content of documents change given the perceived  purpose of the document so analysis of only one kind of document can lead to a biased data set. By analyzing separate kinds of document which are intended for use in different environments and have different prospective readers it is hoped that such bias can be mitigated if not avoided. These documents have a diverse mix of purposes whilst retaining the authority of authors who are experienced if not experts in their fields .

This sample does not represent all tools evenly as the amount of documents surrounding the tools depends on how long the tool has been in development and the degree of funding it has had over that time. That being said there is at least an instructional document from each tool in this data set.

#### Data Processing

These documents are made as part of the production process of these tools and as such can provide a rich source of data as to the environment that they envision creating. The documents in this study are not considered to be static entities but rather are situated within the context of the documents surrounding them [(Prior, 2003](/document-analysis-quotes){: .internal-link}. This is why, when available, this study uses multiple documents pertaining to a single technology, to help situate the individual documents in the process by which they were created.  

The coding of this data will pay special attention to the distinction between the production, consumption and content of this data [(Prior, 2003)](/document-analysis-quotes){: .internal-link}. For production for example it is important to consider how a document is put together, a physical instruction manual may have a single author and be published at a single point however most of these online manuals are continually updated by different authors [(Prior, 2003)](/document-analysis-quotes){: .internal-link}. The process through which users find, access and navigate these documents will also be considered. Using separate passes to code these documents from each perspective (see also [[coding]]).

#### Coding

After an initial coding on a subsection of this data set the coding process will be as follows: an initial descriptive code of all materials over several passes, considering the distinction between the production, consumption and content of this data will be conducted, following this and using the conceptual framework for guidance an initial code list will be created and run through several more passes of the data updating the code list where necessary. The codes and memos that result from this process will be grouped and compared to theory in the analysis portion of the essay. 

In the initial coding process it was found to be useful to use a degree of magnitude coding through out the process specifically in the instruction documents. These documents are quite dry and part of the interest in them is the question of who they are written for - what level of technical competency is expected, what problems are anticipated, what queries is this prospective user expected to ask, how are they formulated etc. Many of these codes need to be done manually but things such as the technical complexity of the language may be done programaticaly. This will be explored. As a body it may be fruitful to run this corpus of texts through the text analysis systems themselves.  


## Ethics and limitations

This investigation entails few risks because it is an investigation of behavior via the examination of technologies as social artifacts,  not of individual persons. Additionally there is little risk of revealing proprietary information as all of the data being used is  publicly available data. Furthermore, most of the tools included in this study are either partially or completely open source so proprietary concerns are minimized in any case.